{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# misc. libraries\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# ml libraries\n",
    "from sklearn import cluster, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local dependencies\n",
    "from load import *\n",
    "from helpers import *\n",
    "from plots import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General notes**\n",
    "* The aim is to find out if the tumor is responding to a specific hormone. This response is \"induced\" in mice by treating them with the hormone. In humans we try to find similar expression patterns to determine if the tumor is driven by a certain hormone. In which case we can group such tumors together for more targeted and better treatment. We know that the patients have a certain type of cancer and this is recorded somewhere although we don't have this information now. If we discover a clear clustering, then it will be valuable to see which cancer types each data point (patient) has. If we interpret each cluster as being certain type of cancer instead of a hormone response, then we will misinterpret the results since the genetic expressions (features) are not results\n",
    "* [Patient derived xenograft, Wikipedia](https://en.wikipedia.org/wiki/Patient_derived_xenograft)\n",
    "* [Few useful things to know about ML](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "* Useful magics:\n",
    "  * `%pycat <filename>` to show a syntax-highlighted file\n",
    "  * `%psource <object>` prints the source code for an object (function, for instance)\n",
    "\n",
    "**Notes from Fabio**\n",
    "* The data include: a matrix from our PDX models stimulated with different hormones (estrogen, progesterone and testosterone) - from which I estimated a list of differentially expressed genes to interrogate the patients' datasets - and a matrix from breast cancer patients retrieved from the TCGA (the Cancer Genome Atlas Consortium - published data).\n",
    "* I suggest you to start testing the list of differentially expressed genes on your training data (PDXs, which is labelled with the correct treatment) that you can use as positive control in order to test the performance of your methods (you can estimate the sensitivity and specificity of the methods that you want to use, so that we can have an idea of which method should be in principle better to use in the patients dataset). Once you will be able to correctly discriminate the samples in the training set, then you can start interrogating the patients' matrix.\n",
    "* Keep in mind that one of the early things that we do when dealing with sequencing data is to get rid of genes that show no or \"minor\" expression overall in the dataset. This means that, for those genes that do not reach a given threshold of expression in a number of patients, they are simply excluded from the analysis because they are supposedly not informative and just confounding the further analysis. Therefore, to some degree, we should expect to have differences in the genes that are expressed. \n",
    "* Regarding the patients data I already gave you they should be already normalized, whereas the new patients' dataset that you downloaded from the Internet  you should make sure it is correctly normalized (for this you should more or less have a normal distribution of your counts and more or less the samples - columns- should have a similar number of counts) and then run the analysis. However, I the interpretation of the PCA plot will not be trivial: since these are patients samples they are likely to be heterogeneous and therefore I do not expect to have a clear clustering of the samples based on their cancer type.\n",
    "* [Informations about drugs used to treat breast cancer](https://www.nature.com/articles/d41573-019-00201-w) over the last decades, to give you an idea of the need for a more personalized medicine.\n",
    "* [Small review on personalized medicine and why it should be pursued](https://notendur.hi.is/~vol1/pdx-papers/nejmsb1503104.pdf)\n",
    "* [Patient-derived xenograft models of breast\n",
    "cancer and their predictive power](https://notendur.hi.is/~vol1/pdx-papers/2015%20PDX%20Breast%20Cancer%20Research.pdf)\n",
    "* [A paper from our lab in which there is the description of our PDX (Patient-Derived Xenograft) model - your training dataset](https://notendur.hi.is/~vol1/pdx-papers/2016%20MIND%20for%20Breast%20Cancer%20Sflomos%20Cancer%20Cell.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **DHT:** Dihydrotestosterone is an endogenous androgen sex steroid and hormone\n",
    "+ **E2:** Estradiol (E2), also spelled oestradiol, is an estrogen steroid hormone and the major female sex hormone\n",
    "+ **P4:**  Progesterone (P4) is an endogenous steroid and progestogen sex hormone involved in the menstrual cycle, pregnancy, and embryogenesis of humans and other species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Data loading and manipulation**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load data about differentially expressed genes in the PDX experiment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %psource load_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw information about genes\n",
    "genes = load_genes()\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed list of genes\n",
    "genes_list = load_genes_list()\n",
    "genes_list.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes showing response to two hormones\n",
    "genes_list[genes_list[HORMONES].sum(axis=1) == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load genetic expression levels from the patient derived xenograft (PDX) experiment on mice*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx = load_pdx()\n",
    "pdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load genetic expression levels of tumor patients*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TCGA first tumor-patients dataset\n",
    "patients = load_patients()\n",
    "print(f\"There are {len(patients)} records in the first dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TCGA second tumor-patients dataset\n",
    "patients2 = load_patients2()\n",
    "print(f\"There are {len(patients2)} records in the second dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know beforehand if it is okay to merge the two datasets. They have the same 91 features but we don't know their distributions or how they were normalized. Let's investigate the distribution of features for both patient-datasets in order to evaluate the feasibility of merging the two sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard highly expressed genes to make the plot readable\n",
    "highly_expressed_genes = [\"COL12A1\", \"COL3A1\", \"CPB1\"]\n",
    "\n",
    "pat = patients.drop(columns=highly_expressed_genes)\n",
    "pat2 = patients2.drop(columns=highly_expressed_genes)\n",
    "\n",
    "pat_mean_std = {\"mean\": pat.mean(), \"std\": pat.std()}\n",
    "pat2_mean_std = {\"mean\": pat2.mean(), \"std\": pat2.std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_means_std_patients(pat_mean_std, pat2_mean_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compare the highly expressed genes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_high = patients[highly_expressed_genes]\n",
    "pat2_high = patients2[highly_expressed_genes]\n",
    "\n",
    "pd.DataFrame(\n",
    "    [pat_high.mean(), pat2_high.mean(), pat_high.std(), pat2_high.std()],\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        [(i, j) for i in [\"mean\", \"std\"] for j in [\"first\", \"second\"]]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the standard deviations of features are quite high, which indicates that the values are spread out over a wide range. Genetic expression levels in tumor patients don't appear to follow normal distributions, rather quite heavy-tailed distributions. We note that some features, like `MYBPC1` and `NTR`, have much greater variance in the second dataset. This can perhaps be explained by the fact that the second dataset has more datapoints, so the number of outliers will generally be higher which results in a higher standard deviation. We shall analyze the distribution in more detail just a bit later.\n",
    "\n",
    "To conclude with the analysis of the above plot, we generally see that each feature seems to have a similar distribution in the two datasets. Based on this information we reason it is safe to merge the two sets. Let's call the new dataframe `pats`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = pd.concat([patients, patients2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicates = pats.duplicated(keep=False).sum()\n",
    "print(f\"There are {len(pats)} records in the merged dataframe\")\n",
    "print(f\"There are {num_duplicates} duplicated records in the merged dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the two datasets have 104 entries in common! Presumably, these are 104 unique tumor patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we haven't discovered all duplicated records, since there are some *fuzzy* duplicates which contain floating point precision errors in one dataset and not the other. Here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats_fuzzy_duplicate_example = pats.loc[[197, 1134], :]\n",
    "fuzzy_genes = [\"TPSG1\", \"MAP3K14\"]\n",
    "for g in fuzzy_genes:\n",
    "    print(f\"{g}: {list(pats_fuzzy_duplicate_example[g].values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fix this by rounding all values to 4 decimal places and see how many duplicates there are in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = round(pats, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are 617 entries in common between the two datasets. But wait a minute... that's exactly the number of entries in the first dataset! Let's see if the second dataset contains the entire first dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = pd.concat([pats[pats.duplicated()], round(patients, 4)]).reset_index(drop=True)\n",
    "duplicates.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When concatenating the duplicated entries in the merged dataframe and entries in the first dataframe, once again we get 617 entries in common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop duplicated entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = pats.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Now, we have {len(pats)} unique records in the merged dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we verify that no expression values are negative or `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats[pats < 0 | pats.isna()].any(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let's now analyze the distribution of the features (genetic expressions) on boxplots. **Todo: Should we eliminate outliers? If yes, then how?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distributions(pats, \"feature_distribution_p1+p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Not all of the genes that were strongly expressed in the PDX experiment did also show strong expression within a broad sample of tumor patients. This is what is to be expected, especially when taking into account that we are comparing data on human patients with data from a xenograft experiment. This is why the loading function of the patient dataset only keeps genes in common with the PDX dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_expressed = patients.columns\n",
    "genes_not_found = genes_list.genes[~genes_list.genes.isin(genes_expressed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of differentially expressed genes:    {len(genes_list.genes)}\")\n",
    "print(f\"Number of which found in the patients dataset:     {len(genes_expressed)}\")\n",
    "print(f\"Number of which not found in the patients dataset: {len(genes_not_found)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Exploratory data analysis**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the correlation between features in the first patients dataset. We shall plot a heatmap to visualize the lower triangular Pearson correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %psource df_to_tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats_corr = df_to_tril(pats.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(pats_corr, genes_expressed, \"corr_patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that most of the genes are relatively uncorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which pairs of genes are highly correlated? We define our correlation threshold to be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR_THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find all pairs of genes differentially expressed upon the same treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %psource gene_pairs_per_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_pairs = gene_pairs_per_treatment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we find the highly correlated pairs of genes in the patients dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pairs of highly correlated genes\n",
    "pats_corr_genes = pats_corr[pats_corr > CORR_THRESHOLD].stack()\n",
    "\n",
    "# Turn the multi-index into a normal index,\n",
    "# give the series a name and then sort it in a descending order\n",
    "pats_corr_genes.index = pats_corr_genes.index.tolist()\n",
    "pats_corr_genes.name = \"patients_correlation\"\n",
    "pats_corr_genes.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two sets of pairs to find pairs present in both sets\n",
    "(\n",
    "    pd.DataFrame(pats_corr_genes)\n",
    "    .join(genes_pairs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appear to be many correlations in the patient dataset that match the PDX data. Note that `NaN` means the two genes showed expressions from different hormone treatments in the PDX experiment, i.e. the correlation does not match the PDX results.\n",
    "\n",
    "Does this not confirm the potentiality of transferring what has been learned in the PDX experiment to tumor patients? Can we conclude that we can expect consistent results when we run the methods trained on the PDX data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Feature processing**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to reduce the dimensionality of the input space, i.e. the linear mapping of our D-dimensional input into a K-dimensional space K<=D that best represents the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA decomposition of original gene list\n",
    "# we want to verify that the pre-selected genes are linearly independent\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(pdx)\n",
    "PCA(copy=True, iterated_power=\"auto\", svd_solver=\"auto\", tol=0.0, whiten=False)\n",
    "\n",
    "y_pos = np.arange(len(pca.singular_values_))\n",
    "plt.bar(y_pos, pca.singular_values_, align=\"center\", alpha=0.5)\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xlabel(\"Principal components\")\n",
    "plt.title(\"PCA - Singular values\")\n",
    "plt.show()\n",
    "\n",
    "y_pos = np.arange(len(pca.singular_values_))\n",
    "plt.bar(y_pos, pca.explained_variance_, align=\"center\", alpha=0.5)\n",
    "plt.ylabel(\"Explained variance\")\n",
    "plt.xlabel(\"Principal components\")\n",
    "plt.title(\"PCA - explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data explained by 2nd and 3rd principal component\n",
    "pca.n_components = 3\n",
    "X_reduced = pca.fit_transform(pdx)\n",
    "X_reduced = np.append(X_reduced, pdx.label.values.reshape((33, 1)), axis=1)\n",
    "plt.plot(X_reduced[:3, b1], X_reduced[:3, 2], \"ro\")\n",
    "plt.plot(X_reduced[3:14, 1], X_reduced[3:14, 2], \"bo\")\n",
    "plt.plot(X_reduced[14:23, 1], X_reduced[14:23, 2], \"co\")\n",
    "plt.plot(X_reduced[23:, 1], X_reduced[23:, 2], \"go\")\n",
    "plt.legend(HORMONES_CTRL)\n",
    "# plt.plot(X_reduced[23:,1], X_reduced[24:,2], 'yo')\n",
    "# plt.legend(['dht', 'p4', 'e2', 'ctrl'])\n",
    "plt.xlabel(\"2nd PC\")\n",
    "plt.ylabel(\"3rd PC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive 3D plot of first 3 principal components\n",
    "\n",
    "# uncomment below line to have interactive plot!\n",
    "# %matplotlib notebook\n",
    "\n",
    "pca.n_components = 3\n",
    "X_reduced = pca.fit_transform(pdx)\n",
    "labels = pdx.label.values.reshape((33, 1))\n",
    "X_reduced = np.append(X_reduced, labels, axis=1)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "Axes3D.scatter(ax, X_reduced[:3, 0], X_reduced[:3, 1], X_reduced[:3, 2])\n",
    "Axes3D.scatter(ax, X_reduced[3:14, 0], X_reduced[3:14, 1], X_reduced[3:14, 2])\n",
    "Axes3D.scatter(ax, X_reduced[14:23, 0],\n",
    "               X_reduced[14:23, 1], X_reduced[14:23, 2])\n",
    "# Axes3D.scatter(ax, X_reduced[23:,0], X_reduced[23:,1], X_reduced[23:,2])\n",
    "ax.set_xlabel(\"1st PC\")\n",
    "ax.set_ylabel(\"2nd PC\")\n",
    "ax.set_zlabel(\"3rd PC\")\n",
    "ax.legend(HORMONES)\n",
    "# ax.legend(['dht', 'p4', 'e2', 'ctrl'])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(pdx)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(0, 33, step=1)\n",
    "y = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.ylim(0.3, 1.1)\n",
    "plt.plot(xi, y, marker=\"o\", linestyle=\"--\", color=\"b\")\n",
    "\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.xticks(\n",
    "    np.arange(0, 33, step=1)\n",
    ")  # change from 0-based array index to 1-based human-readable label\n",
    "plt.ylabel(\"Cumulative variance (%)\")\n",
    "plt.title(\"The number of components needed to explain variance\")\n",
    "\n",
    "plt.axhline(y=0.99, color=\"r\", linestyle=\"-\")\n",
    "plt.axhline(y=0.95, color=\"orange\", linestyle=\"-\")\n",
    "\n",
    "plt.text(0.5, 1, \"99% cut-off threshold\", color=\"red\", fontsize=10)\n",
    "plt.text(0.5, 0.9, \"95% cut-off threshold\", color=\"orange\", fontsize=10)\n",
    "\n",
    "ax.grid(axis=\"x\")\n",
    "plt.show()\n",
    "\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Clustering**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pdx.drop(\"label\", axis=1)\n",
    "pdx_labeled = pdx.label\n",
    "\n",
    "# , affinity='manhattan', linkage='average')\n",
    "clus = cluster.AgglomerativeClustering(n_clusters=4)\n",
    "predicted = clus.fit_predict(X)\n",
    "\n",
    "# calculate score\n",
    "score = metrics.adjusted_rand_score(pdx_labeled, predicted)\n",
    "print(score)\n",
    "# accuracy, f2 = performance(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Spectral Clustering**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = cluster.SpectralClustering(\n",
    "    assign_labels=\"discretize\", n_clusters=4, random_state=0).fit(X)\n",
    "print(\"predicted labels : \" + str(clustering.labels_))\n",
    "print(\"true labels :      \" + str(pdx_labeled.values))\n",
    "print(\"Score : \" + str(metrics.adjusted_rand_score(pdx_labeled, clustering.labels_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**K-Means**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "print(\"predicted labels : \" + str(kmeans.labels_))\n",
    "print(\"true labels :      \" + str(pdx_labeled.values))\n",
    "print(\"Score : \" + str(metrics.adjusted_rand_score(pdx_labeled, kmeans.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should rather evaluate with the metrics.adjusted_rand_score function\n",
    "\n",
    "\n",
    "def performance(labels):\n",
    "    \"\"\"Evaluate performance of predicted cluster compared to pre-selected gene list\"\"\"\n",
    "    # get gene list\n",
    "    geneNP = (\n",
    "        genes_list.loc[:, \"dht\":\"p4\"].astype(int).values\n",
    "    )  # replace with Boolean values\n",
    "\n",
    "    nb_clusters = len(np.unique(labels))\n",
    "    accuracy = np.zeros([nb_clusters, 3])\n",
    "    f2 = np.zeros([nb_clusters, 3])\n",
    "    beta = 2\n",
    "    for i in np.arange(nb_clusters):\n",
    "        label = np.zeros_like(labels)\n",
    "        label[labels == i] = 1\n",
    "        for j in np.arange(geneNP.shape[1]):\n",
    "            # plot confusion matrices\n",
    "\n",
    "            # cm = metrics.confusion_matrix(geneNP[:,j], label)\n",
    "            # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            # fig, ax = plt.subplots()\n",
    "            # im = ax.imshow(cm, interpolation='nearest')\n",
    "            # ax.figure.colorbar(im, ax=ax)\n",
    "            accuracy[i, j] = np.mean(geneNP[:, j] == label)\n",
    "            f2[i, j] = metrics.fbeta_score(geneNP[:, j], label, beta)\n",
    "    return accuracy, f2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
