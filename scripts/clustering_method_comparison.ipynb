{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local dependencies\n",
    "from load import *\n",
    "from plots import *\n",
    "from clustering_helpers import *\n",
    "from constants import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Cluster analysis**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will perform cluster analysis on both the PDX and the tumor patient datasets. To support the interpretation and evaluation of clustering models, we will compute the [silhouette coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) and the [Davis-Boudin index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html). For the PDX dataset we will also compute the [adjusted Rand index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html).\n",
    "The clustering methods used for the analysis are [Agglomerative Clustering](), [K-means](), and [Spectral Clustering]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PDX dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx = load_pdx()\n",
    "X_pdx = pdx.drop(columns=\"label\")\n",
    "y_pdx = pdx.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_all_methods(X_pdx, y_pdx, with_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pdx_stdized = pdx_standardize(X_pdx)\n",
    "X_pdx_stdized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = cluster.KMeans(n_clusters=4, random_state=78)\n",
    "predicted = clus.fit_predict(X_pdx_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_prediction(predicted, y_pdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_all_methods(X_pdx_stdized, y_pdx, with_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Patient dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients2 = load_patients2()\n",
    "pats_log = np.log(patients2 + .1)  # add a small constant because log(0) is undefined\n",
    "pats_log_stdized = df_standardize_columns(pats_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note: the cell below takes a long time due to spectral clustering's O(n<sup>3</sup>) complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_all_methods(pats_log_stdized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about a little PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_pdx_stdized)\n",
    "\n",
    "plot_pca_expl_var(pca)\n",
    "\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pdx_stdized_noctrl = X_pdx_stdized.drop('ctrl')\n",
    "X_pdx_stdized_noctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx_components = pca.transform(X_pdx_stdized_noctrl)\n",
    "pdx_pca = pdx_components[:,:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = cluster.KMeans(n_clusters=3, random_state=1)\n",
    "predicted = clus.fit_predict(pdx_pca)\n",
    "\n",
    "sscore = metrics.adjusted_rand_score(y_pdx_noctrl, predicted)\n",
    "silhouette = metrics.silhouette_score(pdx_pca, predicted, metric='euclidean')\n",
    "db = metrics.davies_bouldin_score(pdx_pca, predicted)\n",
    "\n",
    "sprint(\"score is: \" + str(score))\n",
    "print(\"silhouette is: \" + str(silhouette))\n",
    "print(\"db is: \" + str(db))\n",
    "\n",
    "data = pd.DataFrame(pdx_pca[:,:3], columns=[\"1st PC\", \"2nd PC\", \"3rd PC\"])\n",
    "data['predicted'] = y_pdx_noctrl.values\n",
    "px.scatter_3d(data, x=\"1st PC\", y=\"2nd PC\", z=\"3rd PC\", color='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize for ARI score\n",
    "\n",
    "score = np.zeros((400,5))\n",
    "for j in range(score.shape[1]):\n",
    "    for i in range(score.shape[0]):\n",
    "        clus = cluster.KMeans(n_clusters=j+2, random_state=i)\n",
    "        predicted = clus.fit_predict(pdx_pca)\n",
    "        score[i,j] = metrics.adjusted_rand_score(y_pdx, predicted)\n",
    "    \n",
    "for sc in range(score.shape[1]):\n",
    "    plt.plot(score[:,sc])\n",
    "plt.legend(['2','3','4','5','6'])\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel('Random state initializer')\n",
    "plt.ylabel('ARI score')\n",
    "plt.show()\n",
    "print(score.max())\n",
    "print(np.where(score==score.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(score.shape[1]):\n",
    "    print(\"Max ARI score for \" + str(i+2)+ \" clusters: \" + str(np.round(100*score[:,i].max()))+str('%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(pats_log_stdized)\n",
    "\n",
    "plot_pca_expl_var(pca, 91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 67 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats_components = pca.transform(pats_log_stdized)\n",
    "pats_pca = pats_components[:,:68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = cluster.KMeans(n_clusters=4, random_state=0)\n",
    "predicted = clus.fit_predict(pats_pca)\n",
    "\n",
    "silhouette = metrics.silhouette_score(pats_pca, predicted, metric='euclidean')\n",
    "db = metrics.davies_bouldin_score(pats_pca, predicted)\n",
    "\n",
    "print(\"silhouette is: \" + str(silhouette))\n",
    "print(\"db is: \" + str(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pats_pca[:,:3], columns=[\"1st PC\", \"2nd PC\", \"3rd PC\"])\n",
    "data['predicted'] = predicted\n",
    "px.scatter_3d(data, x=\"1st PC\", y=\"2nd PC\", z=\"3rd PC\", color='predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we get results comparable to the standardized datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
