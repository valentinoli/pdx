{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local dependencies\n",
    "from load import *\n",
    "from plots import *\n",
    "from clustering_helpers import *\n",
    "from constants import *\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Cluster analysis**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will perform cluster analysis on both the PDX and the tumor patient datasets. Before reading this notebook, please make sure you have read the exploratory [data analysis](data_analysis.ipynb). To support the interpretation and evaluation of clustering models, we will compute the [silhouette coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) and the [Davis-Boudin index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html). For the labeled PDX dataset we will also compute the [adjusted Rand index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html).\n",
    "The clustering methods used here are [Agglomerative Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html), [K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html?highlight=kmeans#sklearn.cluster.KMeans), and [Spectral Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html?highlight=spectralclustering#sklearn.cluster.SpectralClustering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PDX dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first run the analysis on the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx = load_pdx()\n",
    "X_pdx = pdx.drop(columns=\"label\")\n",
    "y_pdx = pdx.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx_scores = run_cluster_analysis(X_pdx, y_pdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx_scores.to_latex(open(\"../results/pdx_scores.tex\", \"w\"))\n",
    "pdx_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the analysis on the standardized data (per tumor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pdx_stdized = pdx_standardize(X_pdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx_stdized_scores = run_cluster_analysis(X_pdx_stdized, y_pdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx_stdized_scores.to_latex(open(\"../results/pdx_stdized_scores.tex\", \"w\"))\n",
    "pdx_stdized_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the ARI score is higher for the standardized data, especially for *K-means*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of clusters we are looking for is 3, since we have three hormones/labels. Let's see how the methods perform without the `ctrl` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pdx_stdized_noctrl = X_pdx_stdized.drop('ctrl')\n",
    "y_pdx_noctrl = y_pdx.drop('ctrl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will find the optimal initial centroids for K-means and Spectral clustering, and then apply those optimal centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_opt_state = optimize_ARI(X_pdx_stdized_noctrl, y_pdx_noctrl, n=120, method=\"kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_opt_state = optimize_ARI(X_pdx_stdized_noctrl, y_pdx_noctrl, n=120, method=\"spectral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_random_states = {\n",
    "    \"kmeans\": kmeans_opt_state,\n",
    "    \"spectral\": spectral_opt_state,\n",
    "}\n",
    "pdx_stdized_noctrl_scores = run_cluster_analysis(X_pdx_stdized_noctrl, y_pdx_noctrl, opt_random_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdx_stdized_noctrl_scores.to_latex(open(\"../results/pdx_stdized_noctrl_scores.tex\", \"w\"))\n",
    "pdx_stdized_noctrl_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the methods are better able to cluster when we drop the `ctrl` subjects and use optimum initial centroids. We also observe that the optimal number of clusters is k=3, just as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Patient dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = load_patients2()\n",
    "pats_log_stdized = df_log_standardize_cols(pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pats_scores = run_cluster_analysis(pats_log_stdized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pats_scores.to_latex(open(\"../results/pats_scores.tex\", \"w\"))\n",
    "#pats_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Applying the best method**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll apply K-means using 3 clusters on both the PDX and patient datasets. Note, that the optimal random state for the PDX data cannot be applied to the patient data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PDX dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = cluster.KMeans(n_clusters=3, random_state=116)\n",
    "predicted = clus.fit_predict(X_pdx_stdized_noctrl)\n",
    "\n",
    "ari_score = metrics.adjusted_rand_score(y_pdx_noctrl, predicted)\n",
    "\n",
    "describe_prediction(predicted, y_pdx_noctrl)\n",
    "\n",
    "print(f\"ARI score: {ari_score}\")\n",
    "\n",
    "pca = PCA()\n",
    "pdx_components = pca.fit_transform(X_pdx_stdized_noctrl)\n",
    "data = pd.DataFrame(pdx_components[:, :3], columns=[\"1st PC\", \"2nd PC\", \"3rd PC\"])\n",
    "data[\"predicted\"] = y_pdx_noctrl.values\n",
    "px.scatter_3d(data, x=\"1st PC\", y=\"2nd PC\", z=\"3rd PC\", color=\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = optimize_ARI(X_pdx_stdized_noctrl, y_pdx_noctrl, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_labels = apply_pdx_centroids_on_patients(X_pdx_stdized_noctrl, y_pdx_noctrl, pats_log_stdized, 116, 2)\n",
    "print(patients_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_gene_ratios(pats_log_stdized, patients_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Patient dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(pats_log_stdized)\n",
    "\n",
    "plot_pca_expl_var(pca, 91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 67 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats_components = pca.transform(pats_log_stdized)\n",
    "pats_pca = pats_components[:,:68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = cluster.KMeans(n_clusters=3, random_state=116)\n",
    "predicted = clus.fit_predict(pats_pca)\n",
    "silhouette = metrics.silhouette_score(pats_pca, predicted, metric='euclidean')\n",
    "db = metrics.davies_bouldin_score(pats_pca, predicted)\n",
    "\n",
    "print(\"silhouette is: \" + str(silhouette))\n",
    "print(\"db is: \" + str(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pats_pca[:,:3], columns=[\"1st PC\", \"2nd PC\", \"3rd PC\"])\n",
    "data['predicted'] = predicted\n",
    "px.scatter_3d(data, x=\"1st PC\", y=\"2nd PC\", z=\"3rd PC\", color='predicted')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we get results comparable to the standardized datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
